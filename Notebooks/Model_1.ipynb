{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4974d36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:05.533043Z",
     "iopub.status.busy": "2023-12-03T04:25:05.532524Z",
     "iopub.status.idle": "2023-12-03T04:25:08.747596Z",
     "shell.execute_reply": "2023-12-03T04:25:08.746053Z"
    },
    "papermill": {
     "duration": 3.231271,
     "end_time": "2023-12-03T04:25:08.750814",
     "exception": false,
     "start_time": "2023-12-03T04:25:05.519543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Import Complete****\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords, cmudict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "import shutil\n",
    "print('****Import Complete****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623d7005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:08.769597Z",
     "iopub.status.busy": "2023-12-03T04:25:08.767841Z",
     "iopub.status.idle": "2023-12-03T04:25:09.032351Z",
     "shell.execute_reply": "2023-12-03T04:25:09.030996Z"
    },
    "papermill": {
     "duration": 0.278028,
     "end_time": "2023-12-03T04:25:09.036569",
     "exception": false,
     "start_time": "2023-12-03T04:25:08.758541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging Data Sets\n",
    "human_data = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\n",
    "gpt3_data = pd.read_csv('/kaggle/input/llm-generated-essays/ai_generated_train_essays.csv') \n",
    "gpt4_data = pd.read_csv('/kaggle/input/llm-generated-essays/ai_generated_train_essays_gpt-4.csv')\n",
    "df = pd.concat([human_data,gpt3_data,gpt4_data])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96942a0",
   "metadata": {
    "papermill": {
     "duration": 0.007452,
     "end_time": "2023-12-03T04:25:09.055140",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.047688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Readability Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746ec53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:34:48.608250Z",
     "iopub.status.busy": "2023-12-02T22:34:48.607893Z",
     "iopub.status.idle": "2023-12-02T22:34:50.005716Z",
     "shell.execute_reply": "2023-12-02T22:34:50.004586Z",
     "shell.execute_reply.started": "2023-12-02T22:34:48.608219Z"
    },
    "papermill": {
     "duration": 0.007772,
     "end_time": "2023-12-03T04:25:09.071020",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.063248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Syllable count in a word\n",
    "def syllable_count(word, d):\n",
    "    if word.lower() in d:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    else:\n",
    "        # Fallback method for words not in cmudict\n",
    "        return len(re.findall(r'[aeiouy]+', word.lower()))\n",
    "# Initialize CMU Pronouncing Dictionary\n",
    "d = cmudict.dict()\n",
    "\n",
    "# Helper function to preprocess text and count syllables, words, and sentences\n",
    "def preprocess_and_count(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    syllables = sum(syllable_count(word, d) for word in words)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len([word for word in words if word.isalpha()])\n",
    "    num_syllables = syllables\n",
    "    num_chars = sum(len(word) for word in words if word.isalpha())\n",
    "    return num_sentences, num_words, num_syllables, num_chars\n",
    "\n",
    "\n",
    "# Flesch Reading Ease\n",
    "def flesch_reading_ease(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "\n",
    "# Flesch-Kincaid Grade Level\n",
    "def flesch_kincaid_grade(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 0.39 * (num_words / num_sentences) + 11.8 * (num_syllables / num_words) - 15.59\n",
    "\n",
    "# Gunning Fog Index\n",
    "def gunning_fog(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    complex_words = sum(syllable_count(word, d) >= 3 for word in word_tokenize(text))\n",
    "    return 0.4 * ((num_words / num_sentences) + 100 * (complex_words / num_words))\n",
    "\n",
    "# SMOG Index\n",
    "def smog_index(text):\n",
    "    num_sentences, _, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 1.043 * (30 * (num_syllables / num_sentences))**0.5 + 3.1291\n",
    "\n",
    "# Automated Readability Index\n",
    "def automated_readability_index(text):\n",
    "    num_sentences, num_words, _, num_chars = preprocess_and_count(text)\n",
    "    return 4.71 * (num_chars / num_words) + 0.5 * (num_words / num_sentences) - 21.43\n",
    "\n",
    "# Coleman-Liau Index\n",
    "def coleman_liau_index(text):\n",
    "    num_sentences, num_words, _, num_chars = preprocess_and_count(text)\n",
    "    L = (num_chars / num_words) * 100\n",
    "    S = (num_sentences / num_words) * 100\n",
    "    return 0.0588 * L - 0.296 * S - 15.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3a55c",
   "metadata": {
    "papermill": {
     "duration": 0.008198,
     "end_time": "2023-12-03T04:25:09.101955",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.093757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentence Length Variability Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2925e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:34:50.007725Z",
     "iopub.status.busy": "2023-12-02T22:34:50.007249Z",
     "iopub.status.idle": "2023-12-02T22:38:43.847024Z",
     "shell.execute_reply": "2023-12-02T22:38:43.845846Z",
     "shell.execute_reply.started": "2023-12-02T22:34:50.007678Z"
    },
    "papermill": {
     "duration": 0.008605,
     "end_time": "2023-12-03T04:25:09.118449",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.109844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse each essay into a list of words\n",
    "df['parse'] = df['text'].str.split()\n",
    "# Score each essay on Setence Length Variability\n",
    "df['SLV'] = df['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Score each essay on Setence Length Variability\n",
    "df['SLV'] = df['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Remove Parse Data\n",
    "df.drop(['parse'], axis=1, inplace=True)\n",
    "df.SLV\n",
    "\n",
    "# Parse each essay into a list of words\n",
    "df_test['parse'] = df_test['text'].str.split()\n",
    "# Score each essay on Setence Length Variability\n",
    "df_test['SLV'] = df_test['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Score each essay on Setence Length Variability\n",
    "df_test['SLV'] = df_test['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Remove Parse Data\n",
    "df_test.drop(['parse'], axis=1, inplace=True)\n",
    "df_test.SLV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2171d4",
   "metadata": {
    "papermill": {
     "duration": 0.009306,
     "end_time": "2023-12-03T04:25:09.137555",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.128249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conjunction Count Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212d6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:38:43.851576Z",
     "iopub.status.busy": "2023-12-02T22:38:43.850831Z",
     "iopub.status.idle": "2023-12-02T22:38:44.842619Z",
     "shell.execute_reply": "2023-12-02T22:38:44.841460Z",
     "shell.execute_reply.started": "2023-12-02T22:38:43.851516Z"
    },
    "papermill": {
     "duration": 0.00722,
     "end_time": "2023-12-03T04:25:09.152957",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.145737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conjunctions = [\n",
    "    \"and\", \"but\", \"or\", \"so\", \"yet\", \"nor\", \"for\", \"after\", \"although\",\n",
    "    \"as\", \"because\", \"before\", \"if\", \"once\", \"since\", \"that\", \"though\",\n",
    "    \"till\", \"unless\", \"while\", \"where\", \"whether\", \"because of\", \"in order that\",\n",
    "    \"even though\", \"as long as\", \"as soon as\", \"just as\", \"so that\", \"in case\",\n",
    "    \"now that\", \"as if\", \"provided that\", \"whereas\", \"inasmuch as\", \"whenever\",\n",
    "    \"until\", \"while\", \"after all\", \"as though\", \"lest\", \"regardless\", \"apart from\",\n",
    "    \"given that\", \"if only\", \"in case that\", \"in spite of\", \"on the condition that\",\n",
    "    \"only if\", \"supposing\", \"as far as\", \"in the event that\", \"not to mention\",\n",
    "    \"rather than\", \"such that\", \"to the extent that\", \"although\", \"despite\",\n",
    "    \"much as\", \"whether or not\", \"assuming that\", \"besides\", \"conversely\",\n",
    "    \"except that\", \"in order to\", \"like\", \"provided\", \"save that\", \"that is to say\",\n",
    "    \"to the end that\", \"wherever\", \"whiles\", \"by the time\", \"even if\",\n",
    "    \"on condition that\", \"so long as\", \"apart from that\", \"even when\", \"if then\",\n",
    "    \"in as much as\", \"in spite of the fact that\", \"in the same way that\",\n",
    "    \"not only but also\", \"notwithstanding\", \"presuming that\", \"rather\", \"seeing that\",\n",
    "    \"unless and until\", \"whereas as\", \"whether or no\", \"as against\", \"as well as\",\n",
    "    \"in accordance with\", \"in addition to\", \"in relation to\", \"in the light of\",\n",
    "    \"not to speak of\", \"regardless of the fact that\", \"so as to\", \"with regard to\"]\n",
    "# Create a new column for the number of conjunctions in each essay\n",
    "df[\"num_conjunctions\"] = np.zeros(len(df))\n",
    "\n",
    "# Use a regular expression to find conjunctions in the text\n",
    "conjunctions_regex = r'\\b(?:' + '|'.join(conjunctions) + r')\\b'\n",
    "\n",
    "# Count occurrences of each conjunction in the 'text' column\n",
    "df['num_conjunctions'] = df['text'].str.count(conjunctions_regex)\n",
    "\n",
    "df.num_conjunctions\n",
    "\n",
    "# Create a new column for the number of conjunctions in each essay\n",
    "df_test[\"num_conjunctions\"] = np.zeros(len(df_test))\n",
    "\n",
    "# Use a regular expression to find conjunctions in the text\n",
    "conjunctions_regex = r'\\b(?:' + '|'.join(conjunctions) + r')\\b'\n",
    "\n",
    "# Count occurrences of each conjunction in the 'text' column\n",
    "df_test['num_conjunctions'] = df_test['text'].str.count(conjunctions_regex)\n",
    "\n",
    "df_test.num_conjunctions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7904f",
   "metadata": {
    "papermill": {
     "duration": 0.008366,
     "end_time": "2023-12-03T04:25:09.169015",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.160649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Readability Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a28b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:38:44.844514Z",
     "iopub.status.busy": "2023-12-02T22:38:44.844142Z",
     "iopub.status.idle": "2023-12-02T22:41:44.613554Z",
     "shell.execute_reply": "2023-12-02T22:41:44.612553Z",
     "shell.execute_reply.started": "2023-12-02T22:38:44.844482Z"
    },
    "papermill": {
     "duration": 0.00733,
     "end_time": "2023-12-03T04:25:09.184352",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.177022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['flesch_reading_ease'] = df['text'].apply(flesch_reading_ease)\n",
    "df['flesch_kincaid_grade'] = df['text'].apply(flesch_kincaid_grade)\n",
    "df['gunning_fog'] = df['text'].apply(gunning_fog)\n",
    "df['smog_index'] = df['text'].apply(smog_index)\n",
    "df['automated_readability_index'] = df['text'].apply(automated_readability_index)\n",
    "df['coleman_liau_index'] = df['text'].apply(coleman_liau_index)\n",
    "\n",
    "# Applying readability tests to each essay\n",
    "df_test['flesch_reading_ease'] = df_test['text'].apply(flesch_reading_ease)\n",
    "df_test['flesch_kincaid_grade'] = df_test['text'].apply(flesch_kincaid_grade)\n",
    "df_test['gunning_fog'] = df_test['text'].apply(gunning_fog)\n",
    "df_test['smog_index'] = df_test['text'].apply(smog_index)\n",
    "df_test['automated_readability_index'] = df_test['text'].apply(automated_readability_index)\n",
    "df_test['coleman_liau_index'] = df_test['text'].apply(coleman_liau_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3e968",
   "metadata": {
    "papermill": {
     "duration": 0.007214,
     "end_time": "2023-12-03T04:25:09.199041",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.191827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scaling Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bf66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:41:44.615082Z",
     "iopub.status.busy": "2023-12-02T22:41:44.614776Z",
     "iopub.status.idle": "2023-12-02T22:41:44.667260Z",
     "shell.execute_reply": "2023-12-02T22:41:44.666387Z",
     "shell.execute_reply.started": "2023-12-02T22:41:44.615056Z"
    },
    "papermill": {
     "duration": 0.007357,
     "end_time": "2023-12-03T04:25:09.229526",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.222169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scale numerical data\n",
    "scaler = MinMaxScaler()\n",
    "columns_scale = df.drop(['text', 'generated','id'], axis=1).columns\n",
    "scaled_data = scaler.fit_transform(df[columns_scale])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=columns_scale)\n",
    "df_scaled = pd.concat([df[['id','prompt_id','text']],scaled_df], axis=1)\n",
    "\n",
    "\n",
    "#scale numerical data\n",
    "scaler = MinMaxScaler()\n",
    "columns_test_scale = df_test.drop(['text','id'], axis=1).columns\n",
    "scaled_test_data = scaler.fit_transform(df_test[columns_test_scale])\n",
    "scaled_test_df = pd.DataFrame(scaled_test_data, columns=columns_test_scale)\n",
    "df_test_scaled = pd.concat([df_test[['id','prompt_id','text']],scaled_test_df], axis=1)\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4590a",
   "metadata": {
    "papermill": {
     "duration": 0.007173,
     "end_time": "2023-12-03T04:25:09.244325",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.237152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Text Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf27a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:09.264500Z",
     "iopub.status.busy": "2023-12-03T04:25:09.263810Z",
     "iopub.status.idle": "2023-12-03T04:25:10.780924Z",
     "shell.execute_reply": "2023-12-03T04:25:10.779515Z"
    },
    "papermill": {
     "duration": 1.532049,
     "end_time": "2023-12-03T04:25:10.784074",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.252025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "x_tfidf = tfidf_vectorizer.fit_transform(df['text'])\n",
    "# Combine with Aditional Features\n",
    "combined_x = scipy.sparse.hstack([x_tfidf, df.drop(['id','prompt_id','text'], axis=1).values])\n",
    "\n",
    "x_test_tfidf = tfidf_vectorizer.transform(df_test['text'])\n",
    "# Combine with Aditional Features\n",
    "combined_test_x = scipy.sparse.hstack([x_test_tfidf, df_test.drop(['id','text'], axis=1).values])\n",
    "print(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447183fb",
   "metadata": {
    "papermill": {
     "duration": 0.007217,
     "end_time": "2023-12-03T04:25:10.799414",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.792197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Polish final secitons for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ec4ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:10.817269Z",
     "iopub.status.busy": "2023-12-03T04:25:10.815762Z",
     "iopub.status.idle": "2023-12-03T04:25:10.821254Z",
     "shell.execute_reply": "2023-12-03T04:25:10.820401Z"
    },
    "papermill": {
     "duration": 0.017182,
     "end_time": "2023-12-03T04:25:10.824022",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.806840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = combined_x\n",
    "X_test = combined_test_x\n",
    "y_train = df['generated']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ec916",
   "metadata": {
    "papermill": {
     "duration": 0.007279,
     "end_time": "2023-12-03T04:25:10.839366",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.832087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17c82e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:10.856839Z",
     "iopub.status.busy": "2023-12-03T04:25:10.856211Z",
     "iopub.status.idle": "2023-12-03T04:25:18.603769Z",
     "shell.execute_reply": "2023-12-03T04:25:18.602281Z"
    },
    "papermill": {
     "duration": 7.759967,
     "end_time": "2023-12-03T04:25:18.607075",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.847108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Support Vector Classifier\n",
    "model = SVC(probability=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19629b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:18.624721Z",
     "iopub.status.busy": "2023-12-03T04:25:18.624313Z",
     "iopub.status.idle": "2023-12-03T04:25:18.637611Z",
     "shell.execute_reply": "2023-12-03T04:25:18.636194Z"
    },
    "papermill": {
     "duration": 0.025456,
     "end_time": "2023-12-03T04:25:18.640423",
     "exception": false,
     "start_time": "2023-12-03T04:25:18.614967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert the COO matrix to CSR format\n",
    "X_test_csr = X_test.tocsr()\n",
    "\n",
    "# Slice the first 5008 features\n",
    "X_test_sliced = X_test_csr[:, :5008]\n",
    "\n",
    "# Now you can use predict_proba on the sliced data\n",
    "probabilities = model.predict_proba(X_test_sliced)[:, 1]\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Ensure this is the correct ID column from your test set\n",
    "    'generated': probabilities\n",
    "})\n",
    "\n",
    "# Save to CSV file\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2460f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:18.658032Z",
     "iopub.status.busy": "2023-12-03T04:25:18.657589Z",
     "iopub.status.idle": "2023-12-03T04:25:18.673998Z",
     "shell.execute_reply": "2023-12-03T04:25:18.673015Z"
    },
    "papermill": {
     "duration": 0.02864,
     "end_time": "2023-12-03T04:25:18.677046",
     "exception": false,
     "start_time": "2023-12-03T04:25:18.648406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.304160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.995713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.169693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  1111bbbb   0.304160\n",
       "1  0000aaaa   0.995713\n",
       "2  2222cccc   0.169693"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3937441,
     "sourceId": 6868189,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.98052,
   "end_time": "2023-12-03T04:25:19.709022",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-03T04:25:01.728502",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
