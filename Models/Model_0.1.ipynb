{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4974d36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:05.533043Z",
     "iopub.status.busy": "2023-12-03T04:25:05.532524Z",
     "iopub.status.idle": "2023-12-03T04:25:08.747596Z",
     "shell.execute_reply": "2023-12-03T04:25:08.746053Z"
    },
    "papermill": {
     "duration": 3.231271,
     "end_time": "2023-12-03T04:25:08.750814",
     "exception": false,
     "start_time": "2023-12-03T04:25:05.519543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Import Complete****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/hunterlanier/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords, cmudict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "nltk.download('cmudict')\n",
    "print('****Import Complete****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623d7005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:08.769597Z",
     "iopub.status.busy": "2023-12-03T04:25:08.767841Z",
     "iopub.status.idle": "2023-12-03T04:25:09.032351Z",
     "shell.execute_reply": "2023-12-03T04:25:09.030996Z"
    },
    "papermill": {
     "duration": 0.278028,
     "end_time": "2023-12-03T04:25:09.036569",
     "exception": false,
     "start_time": "2023-12-03T04:25:08.758541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging Data Sets\n",
    "human_data = pd.read_csv('../Data/train_data.csv')\n",
    "gpt3_data = pd.read_csv('../Data/essays_gpt3.5.csv') \n",
    "gpt4_data = pd.read_csv('../Data/essays_gpt4.csv')\n",
    "df = pd.concat([human_data,gpt3_data,gpt4_data])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_test = pd.read_csv('../Challenge/test_essays.csv')\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96942a0",
   "metadata": {
    "papermill": {
     "duration": 0.007452,
     "end_time": "2023-12-03T04:25:09.055140",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.047688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Readability Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3746ec53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:34:48.608250Z",
     "iopub.status.busy": "2023-12-02T22:34:48.607893Z",
     "iopub.status.idle": "2023-12-02T22:34:50.005716Z",
     "shell.execute_reply": "2023-12-02T22:34:50.004586Z",
     "shell.execute_reply.started": "2023-12-02T22:34:48.608219Z"
    },
    "papermill": {
     "duration": 0.007772,
     "end_time": "2023-12-03T04:25:09.071020",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.063248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Syllable count in a word\n",
    "def syllable_count(word, d):\n",
    "    if word.lower() in d:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    else:\n",
    "        # Fallback method for words not in cmudict\n",
    "        return len(re.findall(r'[aeiouy]+', word.lower()))\n",
    "# Initialize CMU Pronouncing Dictionary\n",
    "d = cmudict.dict()\n",
    "\n",
    "# Helper function to preprocess text and count syllables, words, and sentences\n",
    "def preprocess_and_count(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    syllables = sum(syllable_count(word, d) for word in words)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len([word for word in words if word.isalpha()])\n",
    "    num_syllables = syllables\n",
    "    num_chars = sum(len(word) for word in words if word.isalpha())\n",
    "    return num_sentences, num_words, num_syllables, num_chars\n",
    "\n",
    "\n",
    "# Flesch Reading Ease\n",
    "def flesch_reading_ease(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "\n",
    "# Flesch-Kincaid Grade Level\n",
    "def flesch_kincaid_grade(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 0.39 * (num_words / num_sentences) + 11.8 * (num_syllables / num_words) - 15.59\n",
    "\n",
    "# Gunning Fog Index\n",
    "def gunning_fog(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    complex_words = sum(syllable_count(word, d) >= 3 for word in word_tokenize(text))\n",
    "    return 0.4 * ((num_words / num_sentences) + 100 * (complex_words / num_words))\n",
    "\n",
    "# SMOG Index\n",
    "def smog_index(text):\n",
    "    num_sentences, _, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 1.043 * (30 * (num_syllables / num_sentences))**0.5 + 3.1291\n",
    "\n",
    "# Automated Readability Index\n",
    "def automated_readability_index(text):\n",
    "    num_sentences, num_words, _, num_chars = preprocess_and_count(text)\n",
    "    return 4.71 * (num_chars / num_words) + 0.5 * (num_words / num_sentences) - 21.43\n",
    "\n",
    "# Coleman-Liau Index\n",
    "def coleman_liau_index(text):\n",
    "    num_sentences, num_words, _, num_chars = preprocess_and_count(text)\n",
    "    L = (num_chars / num_words) * 100\n",
    "    S = (num_sentences / num_words) * 100\n",
    "    return 0.0588 * L - 0.296 * S - 15.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3a55c",
   "metadata": {
    "papermill": {
     "duration": 0.008198,
     "end_time": "2023-12-03T04:25:09.101955",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.093757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentence Length Variability Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d2925e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:34:50.007725Z",
     "iopub.status.busy": "2023-12-02T22:34:50.007249Z",
     "iopub.status.idle": "2023-12-02T22:38:43.847024Z",
     "shell.execute_reply": "2023-12-02T22:38:43.845846Z",
     "shell.execute_reply.started": "2023-12-02T22:34:50.007678Z"
    },
    "papermill": {
     "duration": 0.008605,
     "end_time": "2023-12-03T04:25:09.118449",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.109844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.471405\n",
       "1    0.471405\n",
       "2    0.471405\n",
       "Name: SLV, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse each essay into a list of words\n",
    "df['parse'] = df['text'].str.split()\n",
    "# Score each essay on Setence Length Variability\n",
    "df['SLV'] = df['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Score each essay on Setence Length Variability\n",
    "df['SLV'] = df['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Remove Parse Data\n",
    "df.drop(['parse'], axis=1, inplace=True)\n",
    "df.SLV\n",
    "\n",
    "# Parse each essay into a list of words\n",
    "df_test['parse'] = df_test['text'].str.split()\n",
    "# Score each essay on Setence Length Variability\n",
    "df_test['SLV'] = df_test['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Score each essay on Setence Length Variability\n",
    "df_test['SLV'] = df_test['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Remove Parse Data\n",
    "df_test.drop(['parse'], axis=1, inplace=True)\n",
    "df_test.SLV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2171d4",
   "metadata": {
    "papermill": {
     "duration": 0.009306,
     "end_time": "2023-12-03T04:25:09.137555",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.128249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conjunction Count Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5212d6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:38:43.851576Z",
     "iopub.status.busy": "2023-12-02T22:38:43.850831Z",
     "iopub.status.idle": "2023-12-02T22:38:44.842619Z",
     "shell.execute_reply": "2023-12-02T22:38:44.841460Z",
     "shell.execute_reply.started": "2023-12-02T22:38:43.851516Z"
    },
    "papermill": {
     "duration": 0.00722,
     "end_time": "2023-12-03T04:25:09.152957",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.145737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: num_conjunctions, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conjunctions = [\n",
    "    \"and\", \"but\", \"or\", \"so\", \"yet\", \"nor\", \"for\", \"after\", \"although\",\n",
    "    \"as\", \"because\", \"before\", \"if\", \"once\", \"since\", \"that\", \"though\",\n",
    "    \"till\", \"unless\", \"while\", \"where\", \"whether\", \"because of\", \"in order that\",\n",
    "    \"even though\", \"as long as\", \"as soon as\", \"just as\", \"so that\", \"in case\",\n",
    "    \"now that\", \"as if\", \"provided that\", \"whereas\", \"inasmuch as\", \"whenever\",\n",
    "    \"until\", \"while\", \"after all\", \"as though\", \"lest\", \"regardless\", \"apart from\",\n",
    "    \"given that\", \"if only\", \"in case that\", \"in spite of\", \"on the condition that\",\n",
    "    \"only if\", \"supposing\", \"as far as\", \"in the event that\", \"not to mention\",\n",
    "    \"rather than\", \"such that\", \"to the extent that\", \"although\", \"despite\",\n",
    "    \"much as\", \"whether or not\", \"assuming that\", \"besides\", \"conversely\",\n",
    "    \"except that\", \"in order to\", \"like\", \"provided\", \"save that\", \"that is to say\",\n",
    "    \"to the end that\", \"wherever\", \"whiles\", \"by the time\", \"even if\",\n",
    "    \"on condition that\", \"so long as\", \"apart from that\", \"even when\", \"if then\",\n",
    "    \"in as much as\", \"in spite of the fact that\", \"in the same way that\",\n",
    "    \"not only but also\", \"notwithstanding\", \"presuming that\", \"rather\", \"seeing that\",\n",
    "    \"unless and until\", \"whereas as\", \"whether or no\", \"as against\", \"as well as\",\n",
    "    \"in accordance with\", \"in addition to\", \"in relation to\", \"in the light of\",\n",
    "    \"not to speak of\", \"regardless of the fact that\", \"so as to\", \"with regard to\"]\n",
    "# Create a new column for the number of conjunctions in each essay\n",
    "df[\"num_conjunctions\"] = np.zeros(len(df))\n",
    "\n",
    "# Use a regular expression to find conjunctions in the text\n",
    "conjunctions_regex = r'\\b(?:' + '|'.join(conjunctions) + r')\\b'\n",
    "\n",
    "# Count occurrences of each conjunction in the 'text' column\n",
    "df['num_conjunctions'] = df['text'].str.count(conjunctions_regex)\n",
    "\n",
    "df.num_conjunctions\n",
    "\n",
    "# Create a new column for the number of conjunctions in each essay\n",
    "df_test[\"num_conjunctions\"] = np.zeros(len(df_test))\n",
    "\n",
    "# Use a regular expression to find conjunctions in the text\n",
    "conjunctions_regex = r'\\b(?:' + '|'.join(conjunctions) + r')\\b'\n",
    "\n",
    "# Count occurrences of each conjunction in the 'text' column\n",
    "df_test['num_conjunctions'] = df_test['text'].str.count(conjunctions_regex)\n",
    "\n",
    "df_test.num_conjunctions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7904f",
   "metadata": {
    "papermill": {
     "duration": 0.008366,
     "end_time": "2023-12-03T04:25:09.169015",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.160649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Readability Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a28b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:38:44.844514Z",
     "iopub.status.busy": "2023-12-02T22:38:44.844142Z",
     "iopub.status.idle": "2023-12-02T22:41:44.613554Z",
     "shell.execute_reply": "2023-12-02T22:41:44.612553Z",
     "shell.execute_reply.started": "2023-12-02T22:38:44.844482Z"
    },
    "papermill": {
     "duration": 0.00733,
     "end_time": "2023-12-03T04:25:09.184352",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.177022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['flesch_reading_ease'] = df['text'].apply(flesch_reading_ease)\n",
    "df['flesch_kincaid_grade'] = df['text'].apply(flesch_kincaid_grade)\n",
    "df['gunning_fog'] = df['text'].apply(gunning_fog)\n",
    "df['smog_index'] = df['text'].apply(smog_index)\n",
    "df['automated_readability_index'] = df['text'].apply(automated_readability_index)\n",
    "df['coleman_liau_index'] = df['text'].apply(coleman_liau_index)\n",
    "\n",
    "# Applying readability tests to each essay\n",
    "df_test['flesch_reading_ease'] = df_test['text'].apply(flesch_reading_ease)\n",
    "df_test['flesch_kincaid_grade'] = df_test['text'].apply(flesch_kincaid_grade)\n",
    "df_test['gunning_fog'] = df_test['text'].apply(gunning_fog)\n",
    "df_test['smog_index'] = df_test['text'].apply(smog_index)\n",
    "df_test['automated_readability_index'] = df_test['text'].apply(automated_readability_index)\n",
    "df_test['coleman_liau_index'] = df_test['text'].apply(coleman_liau_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3e968",
   "metadata": {
    "papermill": {
     "duration": 0.007214,
     "end_time": "2023-12-03T04:25:09.199041",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.191827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scaling Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4bf66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:41:44.615082Z",
     "iopub.status.busy": "2023-12-02T22:41:44.614776Z",
     "iopub.status.idle": "2023-12-02T22:41:44.667260Z",
     "shell.execute_reply": "2023-12-02T22:41:44.666387Z",
     "shell.execute_reply.started": "2023-12-02T22:41:44.615056Z"
    },
    "papermill": {
     "duration": 0.007357,
     "end_time": "2023-12-03T04:25:09.229526",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.222169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>SLV</th>\n",
       "      <th>num_conjunctions</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74280ec3</td>\n",
       "      <td>0</td>\n",
       "      <td>Has it ever seem hotter than it usually has to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252920</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.807488</td>\n",
       "      <td>0.097257</td>\n",
       "      <td>0.069484</td>\n",
       "      <td>0.130386</td>\n",
       "      <td>0.097983</td>\n",
       "      <td>0.255010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5768f8fe</td>\n",
       "      <td>0</td>\n",
       "      <td>In the wake of our growing concern for the env...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702733</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.273011</td>\n",
       "      <td>0.324275</td>\n",
       "      <td>0.369942</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.283874</td>\n",
       "      <td>0.858715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7c7bd27d</td>\n",
       "      <td>0</td>\n",
       "      <td>Title: Advantages of Limiting Car Usage: Lesso...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798842</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.199762</td>\n",
       "      <td>0.383395</td>\n",
       "      <td>0.393324</td>\n",
       "      <td>0.392102</td>\n",
       "      <td>0.318405</td>\n",
       "      <td>0.828144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1a4eba9e</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I'm much happier this way,\" What caused someo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323966</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.648026</td>\n",
       "      <td>0.217210</td>\n",
       "      <td>0.227747</td>\n",
       "      <td>0.289347</td>\n",
       "      <td>0.212360</td>\n",
       "      <td>0.386995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51f51983</td>\n",
       "      <td>1</td>\n",
       "      <td>[Your Name]\\n[Your Address]\\n[City, State, Zip...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499796</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.434311</td>\n",
       "      <td>0.285572</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>0.318657</td>\n",
       "      <td>0.263126</td>\n",
       "      <td>0.656238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>a154688f</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has numerous advantages tha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363045</td>\n",
       "      <td>0.296610</td>\n",
       "      <td>0.349951</td>\n",
       "      <td>0.290502</td>\n",
       "      <td>0.319677</td>\n",
       "      <td>0.274762</td>\n",
       "      <td>0.246839</td>\n",
       "      <td>0.738766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>f61cd2f3</td>\n",
       "      <td>0</td>\n",
       "      <td>Title: The Benefits of Limiting Car Usage: An ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669209</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.311870</td>\n",
       "      <td>0.353428</td>\n",
       "      <td>0.364838</td>\n",
       "      <td>0.392635</td>\n",
       "      <td>0.312299</td>\n",
       "      <td>0.732552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>8da67e56</td>\n",
       "      <td>1</td>\n",
       "      <td>Senator [Your Senator's Name],\\n\\nI am writing...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615519</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.332301</td>\n",
       "      <td>0.339443</td>\n",
       "      <td>0.352619</td>\n",
       "      <td>0.374863</td>\n",
       "      <td>0.302099</td>\n",
       "      <td>0.726805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>5b98d126</td>\n",
       "      <td>0</td>\n",
       "      <td>The advantages of limiting car usage are becom...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339958</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>0.429220</td>\n",
       "      <td>0.268984</td>\n",
       "      <td>0.308841</td>\n",
       "      <td>0.278706</td>\n",
       "      <td>0.236375</td>\n",
       "      <td>0.652223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>b79db5b8</td>\n",
       "      <td>1</td>\n",
       "      <td>[Your Name]\\n[Your Address]\\n[City, State, ZIP...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.517714</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.386671</td>\n",
       "      <td>0.310817</td>\n",
       "      <td>0.320313</td>\n",
       "      <td>0.345119</td>\n",
       "      <td>0.277676</td>\n",
       "      <td>0.675062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2778 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     74280ec3          0  Has it ever seem hotter than it usually has to...   \n",
       "1     5768f8fe          0  In the wake of our growing concern for the env...   \n",
       "2     7c7bd27d          0  Title: Advantages of Limiting Car Usage: Lesso...   \n",
       "3     1a4eba9e          0  \"I'm much happier this way,\" What caused someo...   \n",
       "4     51f51983          1  [Your Name]\\n[Your Address]\\n[City, State, Zip...   \n",
       "...        ...        ...                                                ...   \n",
       "2773  a154688f          0  Limiting car usage has numerous advantages tha...   \n",
       "2774  f61cd2f3          0  Title: The Benefits of Limiting Car Usage: An ...   \n",
       "2775  8da67e56          1  Senator [Your Senator's Name],\\n\\nI am writing...   \n",
       "2776  5b98d126          0  The advantages of limiting car usage are becom...   \n",
       "2777  b79db5b8          1  [Your Name]\\n[Your Address]\\n[City, State, ZIP...   \n",
       "\n",
       "      prompt_id       SLV  num_conjunctions  flesch_reading_ease  \\\n",
       "0           0.0  0.252920          0.203390             0.807488   \n",
       "1           0.0  0.702733          0.144068             0.273011   \n",
       "2           0.0  0.798842          0.135593             0.199762   \n",
       "3           0.0  0.323966          0.322034             0.648026   \n",
       "4           1.0  0.499796          0.237288             0.434311   \n",
       "...         ...       ...               ...                  ...   \n",
       "2773        0.0  0.363045          0.296610             0.349951   \n",
       "2774        0.0  0.669209          0.228814             0.311870   \n",
       "2775        1.0  0.615519          0.186441             0.332301   \n",
       "2776        0.0  0.339958          0.372881             0.429220   \n",
       "2777        1.0  0.517714          0.254237             0.386671   \n",
       "\n",
       "      flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                 0.097257     0.069484    0.130386   \n",
       "1                 0.324275     0.369942    0.301887   \n",
       "2                 0.383395     0.393324    0.392102   \n",
       "3                 0.217210     0.227747    0.289347   \n",
       "4                 0.285572     0.303239    0.318657   \n",
       "...                    ...          ...         ...   \n",
       "2773              0.290502     0.319677    0.274762   \n",
       "2774              0.353428     0.364838    0.392635   \n",
       "2775              0.339443     0.352619    0.374863   \n",
       "2776              0.268984     0.308841    0.278706   \n",
       "2777              0.310817     0.320313    0.345119   \n",
       "\n",
       "      automated_readability_index  coleman_liau_index  \n",
       "0                        0.097983            0.255010  \n",
       "1                        0.283874            0.858715  \n",
       "2                        0.318405            0.828144  \n",
       "3                        0.212360            0.386995  \n",
       "4                        0.263126            0.656238  \n",
       "...                           ...                 ...  \n",
       "2773                     0.246839            0.738766  \n",
       "2774                     0.312299            0.732552  \n",
       "2775                     0.302099            0.726805  \n",
       "2776                     0.236375            0.652223  \n",
       "2777                     0.277676            0.675062  \n",
       "\n",
       "[2778 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale numerical data\n",
    "scaler = MinMaxScaler()\n",
    "columns_scale = df.drop(['text', 'generated','id'], axis=1).columns\n",
    "scaled_data = scaler.fit_transform(df[columns_scale])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=columns_scale)\n",
    "df_scaled = pd.concat([df[['id','prompt_id','text']],scaled_df], axis=1)\n",
    "\n",
    "\n",
    "#scale numerical data\n",
    "scaler = MinMaxScaler()\n",
    "columns_test_scale = df_test.drop(['text','id'], axis=1).columns\n",
    "scaled_test_data = scaler.fit_transform(df_test[columns_test_scale])\n",
    "scaled_test_df = pd.DataFrame(scaled_test_data, columns=columns_test_scale)\n",
    "df_test_scaled = pd.concat([df_test[['id','prompt_id','text']],scaled_test_df], axis=1)\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4590a",
   "metadata": {
    "papermill": {
     "duration": 0.007173,
     "end_time": "2023-12-03T04:25:09.244325",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.237152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Text Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf27a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:09.264500Z",
     "iopub.status.busy": "2023-12-03T04:25:09.263810Z",
     "iopub.status.idle": "2023-12-03T04:25:10.780924Z",
     "shell.execute_reply": "2023-12-03T04:25:10.779515Z"
    },
    "papermill": {
     "duration": 1.532049,
     "end_time": "2023-12-03T04:25:10.784074",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.252025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "x_tfidf = tfidf_vectorizer.fit_transform(df['text'])\n",
    "# Combine with Aditional Features\n",
    "combined_x = scipy.sparse.hstack([x_tfidf, df.drop(['id','prompt_id','text'], axis=1).values])\n",
    "\n",
    "x_test_tfidf = tfidf_vectorizer.transform(df_test['text'])\n",
    "# Combine with Aditional Features\n",
    "combined_test_x = scipy.sparse.hstack([x_test_tfidf, df_test.drop(['id','text'], axis=1).values])\n",
    "print(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447183fb",
   "metadata": {
    "papermill": {
     "duration": 0.007217,
     "end_time": "2023-12-03T04:25:10.799414",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.792197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Polish final secitons for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ec4ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:10.817269Z",
     "iopub.status.busy": "2023-12-03T04:25:10.815762Z",
     "iopub.status.idle": "2023-12-03T04:25:10.821254Z",
     "shell.execute_reply": "2023-12-03T04:25:10.820401Z"
    },
    "papermill": {
     "duration": 0.017182,
     "end_time": "2023-12-03T04:25:10.824022",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.806840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = combined_x\n",
    "X_test = combined_test_x\n",
    "y_train = df['generated']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ec916",
   "metadata": {
    "papermill": {
     "duration": 0.007279,
     "end_time": "2023-12-03T04:25:10.839366",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.832087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c17c82e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:10.856839Z",
     "iopub.status.busy": "2023-12-03T04:25:10.856211Z",
     "iopub.status.idle": "2023-12-03T04:25:18.603769Z",
     "shell.execute_reply": "2023-12-03T04:25:18.602281Z"
    },
    "papermill": {
     "duration": 7.759967,
     "end_time": "2023-12-03T04:25:18.607075",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.847108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Support Vector Classifier\n",
    "model = SVC(probability=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19629b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:18.624721Z",
     "iopub.status.busy": "2023-12-03T04:25:18.624313Z",
     "iopub.status.idle": "2023-12-03T04:25:18.637611Z",
     "shell.execute_reply": "2023-12-03T04:25:18.636194Z"
    },
    "papermill": {
     "duration": 0.025456,
     "end_time": "2023-12-03T04:25:18.640423",
     "exception": false,
     "start_time": "2023-12-03T04:25:18.614967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 5008 features, but SVC is expecting 5009 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb Cell 19\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_test_sliced \u001b[39m=\u001b[39m X_test_csr[:, :\u001b[39m5008\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Now you can use predict_proba on the sliced data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m probabilities \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_test_sliced)[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Create submission DataFrame\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m submission_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m: df_test[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m],  \u001b[39m# Ensure this is the correct ID column from your test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgenerated\u001b[39m\u001b[39m'\u001b[39m: probabilities\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.1.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m })\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:861\u001b[0m, in \u001b[0;36mBaseSVC.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39m@available_if\u001b[39m(_check_proba)\n\u001b[1;32m    835\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    836\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[39m    The model need to have probability information computed at training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39m    datasets.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    862\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobA_\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobB_\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    863\u001b[0m         \u001b[39mraise\u001b[39;00m NotFittedError(\n\u001b[1;32m    864\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mpredict_proba is not available when fitted with probability=False\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    608\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel):\n\u001b[0;32m--> 611\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    612\u001b[0m         X,\n\u001b[1;32m    613\u001b[0m         accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m         dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64,\n\u001b[1;32m    615\u001b[0m         order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    616\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    617\u001b[0m         reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    618\u001b[0m     )\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39misspmatrix(X):\n\u001b[1;32m    621\u001b[0m     X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 625\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39mreset)\n\u001b[1;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 5008 features, but SVC is expecting 5009 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the COO matrix to CSR format\n",
    "X_test_csr = X_test.tocsr()\n",
    "\n",
    "# Slice the first 5008 features\n",
    "X_test_sliced = X_test_csr[:, :5008]\n",
    "\n",
    "# Now you can use predict_proba on the sliced data\n",
    "probabilities = model.predict_proba(X_test_sliced)[:, 1]\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Ensure this is the correct ID column from your test set\n",
    "    'generated': probabilities\n",
    "})\n",
    "\n",
    "# Save to CSV file\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2460f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:18.658032Z",
     "iopub.status.busy": "2023-12-03T04:25:18.657589Z",
     "iopub.status.idle": "2023-12-03T04:25:18.673998Z",
     "shell.execute_reply": "2023-12-03T04:25:18.673015Z"
    },
    "papermill": {
     "duration": 0.02864,
     "end_time": "2023-12-03T04:25:18.677046",
     "exception": false,
     "start_time": "2023-12-03T04:25:18.648406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hunterlanier/AI-Text-Detection/Notebooks/Model_1.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Notebooks/Model_1.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m submission_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'submission_df' is not defined"
     ]
    }
   ],
   "source": [
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3937441,
     "sourceId": 6868189,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.98052,
   "end_time": "2023-12-03T04:25:19.709022",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-03T04:25:01.728502",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
