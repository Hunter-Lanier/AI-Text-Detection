{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4974d36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:05.533043Z",
     "iopub.status.busy": "2023-12-03T04:25:05.532524Z",
     "iopub.status.idle": "2023-12-03T04:25:08.747596Z",
     "shell.execute_reply": "2023-12-03T04:25:08.746053Z"
    },
    "papermill": {
     "duration": 3.231271,
     "end_time": "2023-12-03T04:25:08.750814",
     "exception": false,
     "start_time": "2023-12-03T04:25:05.519543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Import Complete****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     /Users/hunterlanier/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords, cmudict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "import xgboost as xgb\n",
    "nltk.download('cmudict')\n",
    "print('****Import Complete****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "623d7005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:08.769597Z",
     "iopub.status.busy": "2023-12-03T04:25:08.767841Z",
     "iopub.status.idle": "2023-12-03T04:25:09.032351Z",
     "shell.execute_reply": "2023-12-03T04:25:09.030996Z"
    },
    "papermill": {
     "duration": 0.278028,
     "end_time": "2023-12-03T04:25:09.036569",
     "exception": false,
     "start_time": "2023-12-03T04:25:08.758541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging Data Sets\n",
    "human_data = pd.read_csv('../Data/train_data.csv')\n",
    "gpt3_data = pd.read_csv('../Data/essays_gpt3.5.csv') \n",
    "gpt4_data = pd.read_csv('../Data/essays_gpt4.csv')\n",
    "df = pd.concat([human_data,gpt3_data,gpt4_data])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_test = pd.read_csv('../Challenge/test_essays.csv')\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96942a0",
   "metadata": {
    "papermill": {
     "duration": 0.007452,
     "end_time": "2023-12-03T04:25:09.055140",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.047688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Readability Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3746ec53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:34:48.608250Z",
     "iopub.status.busy": "2023-12-02T22:34:48.607893Z",
     "iopub.status.idle": "2023-12-02T22:34:50.005716Z",
     "shell.execute_reply": "2023-12-02T22:34:50.004586Z",
     "shell.execute_reply.started": "2023-12-02T22:34:48.608219Z"
    },
    "papermill": {
     "duration": 0.007772,
     "end_time": "2023-12-03T04:25:09.071020",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.063248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Syllable count in a word\n",
    "def syllable_count(word, d):\n",
    "    if word.lower() in d:\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in d[word.lower()]])\n",
    "    else:\n",
    "        # Fallback method for words not in cmudict\n",
    "        return len(re.findall(r'[aeiouy]+', word.lower()))\n",
    "# Initialize CMU Pronouncing Dictionary\n",
    "d = cmudict.dict()\n",
    "\n",
    "# Helper function to preprocess text and count syllables, words, and sentences\n",
    "def preprocess_and_count(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    syllables = sum(syllable_count(word, d) for word in words)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len([word for word in words if word.isalpha()])\n",
    "    num_syllables = syllables\n",
    "    num_chars = sum(len(word) for word in words if word.isalpha())\n",
    "    return num_sentences, num_words, num_syllables, num_chars\n",
    "\n",
    "\n",
    "# Flesch Reading Ease\n",
    "def flesch_reading_ease(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 206.835 - 1.015 * (num_words / num_sentences) - 84.6 * (num_syllables / num_words)\n",
    "\n",
    "# Flesch-Kincaid Grade Level\n",
    "def flesch_kincaid_grade(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 0.39 * (num_words / num_sentences) + 11.8 * (num_syllables / num_words) - 15.59\n",
    "\n",
    "# Gunning Fog Index\n",
    "def gunning_fog(text):\n",
    "    num_sentences, num_words, num_syllables, _ = preprocess_and_count(text)\n",
    "    complex_words = sum(syllable_count(word, d) >= 3 for word in word_tokenize(text))\n",
    "    return 0.4 * ((num_words / num_sentences) + 100 * (complex_words / num_words))\n",
    "\n",
    "# SMOG Index\n",
    "def smog_index(text):\n",
    "    num_sentences, _, num_syllables, _ = preprocess_and_count(text)\n",
    "    return 1.043 * (30 * (num_syllables / num_sentences))**0.5 + 3.1291\n",
    "\n",
    "# Automated Readability Index\n",
    "def automated_readability_index(text):\n",
    "    num_sentences, num_words, _, num_chars = preprocess_and_count(text)\n",
    "    return 4.71 * (num_chars / num_words) + 0.5 * (num_words / num_sentences) - 21.43\n",
    "\n",
    "# Coleman-Liau Index\n",
    "def coleman_liau_index(text):\n",
    "    num_sentences, num_words, _, num_chars = preprocess_and_count(text)\n",
    "    L = (num_chars / num_words) * 100\n",
    "    S = (num_sentences / num_words) * 100\n",
    "    return 0.0588 * L - 0.296 * S - 15.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3a55c",
   "metadata": {
    "papermill": {
     "duration": 0.008198,
     "end_time": "2023-12-03T04:25:09.101955",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.093757",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentence Length Variability Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65d2925e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:34:50.007725Z",
     "iopub.status.busy": "2023-12-02T22:34:50.007249Z",
     "iopub.status.idle": "2023-12-02T22:38:43.847024Z",
     "shell.execute_reply": "2023-12-02T22:38:43.845846Z",
     "shell.execute_reply.started": "2023-12-02T22:34:50.007678Z"
    },
    "papermill": {
     "duration": 0.008605,
     "end_time": "2023-12-03T04:25:09.118449",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.109844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Score each essay on Setence Length Variability\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSLV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mstd([\u001b[39mlen\u001b[39m(word_tokenize(sentence)) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m x]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Score each essay on Setence Length Variability\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSLV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mstd([\u001b[39mlen\u001b[39m(word_tokenize(sentence)) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m x]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4520\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4521\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4525\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4526\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4527\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4529\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4630\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Score each essay on Setence Length Variability\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSLV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mstd([\u001b[39mlen\u001b[39m(word_tokenize(sentence)) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m x]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Score each essay on Setence Length Variability\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSLV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mstd([\u001b[39mlen\u001b[39m(word_tokenize(sentence)) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m x]))\n",
      "\u001b[1;32m/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Score each essay on Setence Length Variability\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSLV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mstd([\u001b[39mlen\u001b[39m(word_tokenize(sentence)) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m x]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Score each essay on Setence Length Variability\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSLV\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mparse\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39mstd([\u001b[39mlen\u001b[39m(word_tokenize(sentence)) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m x]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m, preserve_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m    :type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m         token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:107\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mReturn a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39musing NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m:param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtokenizers/punkt/\u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1281\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, realign_boundaries: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m   1278\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[39m    Given a text, returns a list of the sentences in that text.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentences_from_text(text, realign_boundaries))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1341\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.sentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences_from_text\u001b[39m(\n\u001b[1;32m   1333\u001b[0m     \u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, realign_boundaries: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m   1335\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[39m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[39m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[39m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[39m    follows the period.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1341\u001b[0m     \u001b[39mreturn\u001b[39;00m [text[s:e] \u001b[39mfor\u001b[39;00m s, e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1341\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentences_from_text\u001b[39m(\n\u001b[1;32m   1333\u001b[0m     \u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m, realign_boundaries: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m   1335\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[39m    Given a text, generates the sentences in that text by only\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[39m    testing candidate sentence breaks. If realign_boundaries is\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \u001b[39m    True, includes in the sentence closing punctuation that\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m \u001b[39m    follows the period.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1341\u001b[0m     \u001b[39mreturn\u001b[39;00m [text[s:e] \u001b[39mfor\u001b[39;00m s, e \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspan_tokenize(text, realign_boundaries)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1329\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer.span_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[39mif\u001b[39;00m realign_boundaries:\n\u001b[1;32m   1328\u001b[0m     slices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_realign_boundaries(text, slices)\n\u001b[0;32m-> 1329\u001b[0m \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m slices:\n\u001b[1;32m   1330\u001b[0m     \u001b[39myield\u001b[39;00m (sentence\u001b[39m.\u001b[39mstart, sentence\u001b[39m.\u001b[39mstop)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py:1459\u001b[0m, in \u001b[0;36mPunktSentenceTokenizer._realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \u001b[39mAttempts to realign punctuation that falls after the period but\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m \u001b[39mshould otherwise be included in the same sentence.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[39m    [\"(Sent1.)\", \"Sent2.\"].\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m realign \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1459\u001b[0m \u001b[39mfor\u001b[39;00m sentence1, sentence2 \u001b[39min\u001b[39;00m _pair_iter(slices):\n\u001b[1;32m   1460\u001b[0m     sentence1 \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(sentence1\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m realign, sentence1\u001b[39m.\u001b[39mstop)\n\u001b[1;32m   1461\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sentence2:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py:313\u001b[0m, in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39m\"\"\"Matches token types that are not merely punctuation. (Types for\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39mnumeric tokens are changed to ##number## and hence contain alpha.)\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# }\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m######################################################################\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39m# { Helper Functions\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m# ////////////////////////////////////////////////////////////\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pair_iter\u001b[39m(iterator):\n\u001b[1;32m    314\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39m    Yields pairs of tokens from the given iterator such that each input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m    token will appear as the first element in a yielded tuple. The last\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39m    pair will have None as its second element.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(iterator)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parse each essay into a list of words\n",
    "df['parse'] = df['text'].str.split()\n",
    "# Score each essay on Setence Length Variability\n",
    "df['SLV'] = df['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Score each essay on Setence Length Variability\n",
    "df['SLV'] = df['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Remove Parse Data\n",
    "df.drop(['parse'], axis=1, inplace=True)\n",
    "df.SLV\n",
    "\n",
    "# Parse each essay into a list of words\n",
    "df_test['parse'] = df_test['text'].str.split()\n",
    "# Score each essay on Setence Length Variability\n",
    "df_test['SLV'] = df_test['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Score each essay on Setence Length Variability\n",
    "df_test['SLV'] = df_test['parse'].apply(lambda x: np.std([len(word_tokenize(sentence)) for sentence in x]))\n",
    "# Remove Parse Data\n",
    "df_test.drop(['parse'], axis=1, inplace=True)\n",
    "df_test.SLV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2171d4",
   "metadata": {
    "papermill": {
     "duration": 0.009306,
     "end_time": "2023-12-03T04:25:09.137555",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.128249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conjunction Count Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212d6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:38:43.851576Z",
     "iopub.status.busy": "2023-12-02T22:38:43.850831Z",
     "iopub.status.idle": "2023-12-02T22:38:44.842619Z",
     "shell.execute_reply": "2023-12-02T22:38:44.841460Z",
     "shell.execute_reply.started": "2023-12-02T22:38:43.851516Z"
    },
    "papermill": {
     "duration": 0.00722,
     "end_time": "2023-12-03T04:25:09.152957",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.145737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "Name: num_conjunctions, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conjunctions = [\n",
    "    \"and\", \"but\", \"or\", \"so\", \"yet\", \"nor\", \"for\", \"after\", \"although\",\n",
    "    \"as\", \"because\", \"before\", \"if\", \"once\", \"since\", \"that\", \"though\",\n",
    "    \"till\", \"unless\", \"while\", \"where\", \"whether\", \"because of\", \"in order that\",\n",
    "    \"even though\", \"as long as\", \"as soon as\", \"just as\", \"so that\", \"in case\",\n",
    "    \"now that\", \"as if\", \"provided that\", \"whereas\", \"inasmuch as\", \"whenever\",\n",
    "    \"until\", \"while\", \"after all\", \"as though\", \"lest\", \"regardless\", \"apart from\",\n",
    "    \"given that\", \"if only\", \"in case that\", \"in spite of\", \"on the condition that\",\n",
    "    \"only if\", \"supposing\", \"as far as\", \"in the event that\", \"not to mention\",\n",
    "    \"rather than\", \"such that\", \"to the extent that\", \"although\", \"despite\",\n",
    "    \"much as\", \"whether or not\", \"assuming that\", \"besides\", \"conversely\",\n",
    "    \"except that\", \"in order to\", \"like\", \"provided\", \"save that\", \"that is to say\",\n",
    "    \"to the end that\", \"wherever\", \"whiles\", \"by the time\", \"even if\",\n",
    "    \"on condition that\", \"so long as\", \"apart from that\", \"even when\", \"if then\",\n",
    "    \"in as much as\", \"in spite of the fact that\", \"in the same way that\",\n",
    "    \"not only but also\", \"notwithstanding\", \"presuming that\", \"rather\", \"seeing that\",\n",
    "    \"unless and until\", \"whereas as\", \"whether or no\", \"as against\", \"as well as\",\n",
    "    \"in accordance with\", \"in addition to\", \"in relation to\", \"in the light of\",\n",
    "    \"not to speak of\", \"regardless of the fact that\", \"so as to\", \"with regard to\"]\n",
    "# Create a new column for the number of conjunctions in each essay\n",
    "df[\"num_conjunctions\"] = np.zeros(len(df))\n",
    "\n",
    "# Use a regular expression to find conjunctions in the text\n",
    "conjunctions_regex = r'\\b(?:' + '|'.join(conjunctions) + r')\\b'\n",
    "\n",
    "# Count occurrences of each conjunction in the 'text' column\n",
    "df['num_conjunctions'] = df['text'].str.count(conjunctions_regex)\n",
    "\n",
    "df.num_conjunctions\n",
    "\n",
    "# Create a new column for the number of conjunctions in each essay\n",
    "df_test[\"num_conjunctions\"] = np.zeros(len(df_test))\n",
    "\n",
    "# Use a regular expression to find conjunctions in the text\n",
    "conjunctions_regex = r'\\b(?:' + '|'.join(conjunctions) + r')\\b'\n",
    "\n",
    "# Count occurrences of each conjunction in the 'text' column\n",
    "df_test['num_conjunctions'] = df_test['text'].str.count(conjunctions_regex)\n",
    "\n",
    "df_test.num_conjunctions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7904f",
   "metadata": {
    "papermill": {
     "duration": 0.008366,
     "end_time": "2023-12-03T04:25:09.169015",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.160649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Readability Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a28b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:38:44.844514Z",
     "iopub.status.busy": "2023-12-02T22:38:44.844142Z",
     "iopub.status.idle": "2023-12-02T22:41:44.613554Z",
     "shell.execute_reply": "2023-12-02T22:41:44.612553Z",
     "shell.execute_reply.started": "2023-12-02T22:38:44.844482Z"
    },
    "papermill": {
     "duration": 0.00733,
     "end_time": "2023-12-03T04:25:09.184352",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.177022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['flesch_reading_ease'] = df['text'].apply(flesch_reading_ease)\n",
    "df['flesch_kincaid_grade'] = df['text'].apply(flesch_kincaid_grade)\n",
    "df['gunning_fog'] = df['text'].apply(gunning_fog)\n",
    "df['smog_index'] = df['text'].apply(smog_index)\n",
    "df['automated_readability_index'] = df['text'].apply(automated_readability_index)\n",
    "df['coleman_liau_index'] = df['text'].apply(coleman_liau_index)\n",
    "\n",
    "# Applying readability tests to each essay\n",
    "df_test['flesch_reading_ease'] = df_test['text'].apply(flesch_reading_ease)\n",
    "df_test['flesch_kincaid_grade'] = df_test['text'].apply(flesch_kincaid_grade)\n",
    "df_test['gunning_fog'] = df_test['text'].apply(gunning_fog)\n",
    "df_test['smog_index'] = df_test['text'].apply(smog_index)\n",
    "df_test['automated_readability_index'] = df_test['text'].apply(automated_readability_index)\n",
    "df_test['coleman_liau_index'] = df_test['text'].apply(coleman_liau_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3e968",
   "metadata": {
    "papermill": {
     "duration": 0.007214,
     "end_time": "2023-12-03T04:25:09.199041",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.191827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scaling Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bf66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T22:41:44.615082Z",
     "iopub.status.busy": "2023-12-02T22:41:44.614776Z",
     "iopub.status.idle": "2023-12-02T22:41:44.667260Z",
     "shell.execute_reply": "2023-12-02T22:41:44.666387Z",
     "shell.execute_reply.started": "2023-12-02T22:41:44.615056Z"
    },
    "papermill": {
     "duration": 0.007357,
     "end_time": "2023-12-03T04:25:09.229526",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.222169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>SLV</th>\n",
       "      <th>num_conjunctions</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4154d754</td>\n",
       "      <td>0</td>\n",
       "      <td>Advantages of Limiting Car Usage\\n\\nLimiting c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>0.408741</td>\n",
       "      <td>0.279364</td>\n",
       "      <td>0.307874</td>\n",
       "      <td>0.289240</td>\n",
       "      <td>0.246485</td>\n",
       "      <td>0.677825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>743e9f23</td>\n",
       "      <td>1</td>\n",
       "      <td>I argue in favor of keeping the Electoral Coll...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375219</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.634928</td>\n",
       "      <td>0.206408</td>\n",
       "      <td>0.225866</td>\n",
       "      <td>0.263264</td>\n",
       "      <td>0.186149</td>\n",
       "      <td>0.372702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b36d87f5</td>\n",
       "      <td>1</td>\n",
       "      <td>[Your Name]\\n[Your Address]\\n[City, State, Zip...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.460174</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.417743</td>\n",
       "      <td>0.271031</td>\n",
       "      <td>0.278243</td>\n",
       "      <td>0.275788</td>\n",
       "      <td>0.249351</td>\n",
       "      <td>0.713691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f7aa848d</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear senator, I am not in favor of the elector...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.457850</td>\n",
       "      <td>0.330508</td>\n",
       "      <td>0.684419</td>\n",
       "      <td>0.168136</td>\n",
       "      <td>0.169114</td>\n",
       "      <td>0.211579</td>\n",
       "      <td>0.149670</td>\n",
       "      <td>0.334467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38806fc0</td>\n",
       "      <td>1</td>\n",
       "      <td>Since our very first President George Washingt...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.378589</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.593875</td>\n",
       "      <td>0.196474</td>\n",
       "      <td>0.190287</td>\n",
       "      <td>0.219302</td>\n",
       "      <td>0.189902</td>\n",
       "      <td>0.521093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>85b29439</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear The Florida State Senator, In our nation,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448267</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.665618</td>\n",
       "      <td>0.164765</td>\n",
       "      <td>0.177445</td>\n",
       "      <td>0.193086</td>\n",
       "      <td>0.142594</td>\n",
       "      <td>0.361828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>74fe2a5c</td>\n",
       "      <td>1</td>\n",
       "      <td>[Your Name]\\n[Your Address]\\n[City, State, Zip...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.449516</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.394378</td>\n",
       "      <td>0.299548</td>\n",
       "      <td>0.314854</td>\n",
       "      <td>0.325502</td>\n",
       "      <td>0.265323</td>\n",
       "      <td>0.672441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>463ad422</td>\n",
       "      <td>1</td>\n",
       "      <td>Many people feel that the president plays a ve...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317626</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.718808</td>\n",
       "      <td>0.139050</td>\n",
       "      <td>0.138237</td>\n",
       "      <td>0.168666</td>\n",
       "      <td>0.141441</td>\n",
       "      <td>0.383007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>f837fc25</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Senator, The electoral college has existe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.227890</td>\n",
       "      <td>0.237288</td>\n",
       "      <td>0.562964</td>\n",
       "      <td>0.245217</td>\n",
       "      <td>0.266683</td>\n",
       "      <td>0.303931</td>\n",
       "      <td>0.225390</td>\n",
       "      <td>0.462857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>763f9c24</td>\n",
       "      <td>1</td>\n",
       "      <td>[Your Name]\\n[Your Address]\\n[City, State, ZIP...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508985</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.399515</td>\n",
       "      <td>0.284685</td>\n",
       "      <td>0.285249</td>\n",
       "      <td>0.295472</td>\n",
       "      <td>0.251271</td>\n",
       "      <td>0.686858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2778 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     4154d754          0  Advantages of Limiting Car Usage\\n\\nLimiting c...   \n",
       "1     743e9f23          1  I argue in favor of keeping the Electoral Coll...   \n",
       "2     b36d87f5          1  [Your Name]\\n[Your Address]\\n[City, State, Zip...   \n",
       "3     f7aa848d          1  Dear senator, I am not in favor of the elector...   \n",
       "4     38806fc0          1  Since our very first President George Washingt...   \n",
       "...        ...        ...                                                ...   \n",
       "2773  85b29439          1  Dear The Florida State Senator, In our nation,...   \n",
       "2774  74fe2a5c          1  [Your Name]\\n[Your Address]\\n[City, State, Zip...   \n",
       "2775  463ad422          1  Many people feel that the president plays a ve...   \n",
       "2776  f837fc25          1  Dear Senator, The electoral college has existe...   \n",
       "2777  763f9c24          1  [Your Name]\\n[Your Address]\\n[City, State, ZIP...   \n",
       "\n",
       "      prompt_id       SLV  num_conjunctions  flesch_reading_ease  \\\n",
       "0           0.0  0.500800          0.169492             0.408741   \n",
       "1           1.0  0.375219          0.237288             0.634928   \n",
       "2           1.0  0.460174          0.220339             0.417743   \n",
       "3           1.0  0.457850          0.330508             0.684419   \n",
       "4           1.0  0.378589          0.220339             0.593875   \n",
       "...         ...       ...               ...                  ...   \n",
       "2773        1.0  0.448267          0.177966             0.665618   \n",
       "2774        1.0  0.449516          0.322034             0.394378   \n",
       "2775        1.0  0.317626          0.228814             0.718808   \n",
       "2776        1.0  0.227890          0.237288             0.562964   \n",
       "2777        1.0  0.508985          0.220339             0.399515   \n",
       "\n",
       "      flesch_kincaid_grade  gunning_fog  smog_index  \\\n",
       "0                 0.279364     0.307874    0.289240   \n",
       "1                 0.206408     0.225866    0.263264   \n",
       "2                 0.271031     0.278243    0.275788   \n",
       "3                 0.168136     0.169114    0.211579   \n",
       "4                 0.196474     0.190287    0.219302   \n",
       "...                    ...          ...         ...   \n",
       "2773              0.164765     0.177445    0.193086   \n",
       "2774              0.299548     0.314854    0.325502   \n",
       "2775              0.139050     0.138237    0.168666   \n",
       "2776              0.245217     0.266683    0.303931   \n",
       "2777              0.284685     0.285249    0.295472   \n",
       "\n",
       "      automated_readability_index  coleman_liau_index  \n",
       "0                        0.246485            0.677825  \n",
       "1                        0.186149            0.372702  \n",
       "2                        0.249351            0.713691  \n",
       "3                        0.149670            0.334467  \n",
       "4                        0.189902            0.521093  \n",
       "...                           ...                 ...  \n",
       "2773                     0.142594            0.361828  \n",
       "2774                     0.265323            0.672441  \n",
       "2775                     0.141441            0.383007  \n",
       "2776                     0.225390            0.462857  \n",
       "2777                     0.251271            0.686858  \n",
       "\n",
       "[2778 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale numerical data\n",
    "scaler = MinMaxScaler()\n",
    "columns_scale = df.drop(['text', 'generated','id'], axis=1).columns\n",
    "scaled_data = scaler.fit_transform(df[columns_scale])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=columns_scale)\n",
    "df_scaled = pd.concat([df[['id','prompt_id','text']],scaled_df], axis=1)\n",
    "\n",
    "\n",
    "#scale numerical data\n",
    "scaler = MinMaxScaler()\n",
    "columns_test_scale = df_test.drop(['text','id'], axis=1).columns\n",
    "scaled_test_data = scaler.fit_transform(df_test[columns_test_scale])\n",
    "scaled_test_df = pd.DataFrame(scaled_test_data, columns=columns_test_scale)\n",
    "df_test_scaled = pd.concat([df_test[['id','prompt_id','text']],scaled_test_df], axis=1)\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4590a",
   "metadata": {
    "papermill": {
     "duration": 0.007173,
     "end_time": "2023-12-03T04:25:09.244325",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.237152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating Text Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf27a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:09.264500Z",
     "iopub.status.busy": "2023-12-03T04:25:09.263810Z",
     "iopub.status.idle": "2023-12-03T04:25:10.780924Z",
     "shell.execute_reply": "2023-12-03T04:25:10.779515Z"
    },
    "papermill": {
     "duration": 1.532049,
     "end_time": "2023-12-03T04:25:10.784074",
     "exception": false,
     "start_time": "2023-12-03T04:25:09.252025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "x_tfidf = tfidf_vectorizer.fit_transform(df['text'])\n",
    "# Combine with Aditional Features\n",
    "combined_x = scipy.sparse.hstack([x_tfidf, df.drop(['id','prompt_id','text'], axis=1).values])\n",
    "\n",
    "x_test_tfidf = tfidf_vectorizer.transform(df_test['text'])\n",
    "# Combine with Aditional Features\n",
    "combined_test_x = scipy.sparse.hstack([x_test_tfidf, df_test.drop(['id','text'], axis=1).values])\n",
    "print(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447183fb",
   "metadata": {
    "papermill": {
     "duration": 0.007217,
     "end_time": "2023-12-03T04:25:10.799414",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.792197",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Polish final secitons for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28ec4ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:10.817269Z",
     "iopub.status.busy": "2023-12-03T04:25:10.815762Z",
     "iopub.status.idle": "2023-12-03T04:25:10.821254Z",
     "shell.execute_reply": "2023-12-03T04:25:10.820401Z"
    },
    "papermill": {
     "duration": 0.017182,
     "end_time": "2023-12-03T04:25:10.824022",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.806840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = combined_x\n",
    "X_test = combined_test_x\n",
    "y_train = df['generated']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 972 candidates, totalling 2916 fits\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.528 total time=   4.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.511 total time=   5.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1;, score=0.499 total time=   5.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1;, score=0.521 total time=   5.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.508 total time=   5.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=1;, score=0.521 total time=   5.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8;, score=0.513 total time=  10.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8;, score=0.502 total time=  10.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8;, score=0.528 total time=   9.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1;, score=0.519 total time=  10.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1;, score=0.502 total time=  11.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=200, subsample=1;, score=0.515 total time=  11.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8;, score=0.517 total time=  15.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.504 total time=   5.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8;, score=0.510 total time=  15.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.513 total time=   4.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8;, score=0.530 total time=  15.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8;, score=0.526 total time=   4.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1;, score=0.477 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1;, score=0.503 total time=   5.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1;, score=0.517 total time=  16.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=1;, score=0.510 total time=   5.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1;, score=0.498 total time=  17.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=300, subsample=1;, score=0.529 total time=  16.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.8;, score=0.511 total time=   9.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.8;, score=0.506 total time=   9.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.8;, score=0.526 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=1;, score=0.516 total time=  10.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=1;, score=0.485 total time=  10.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=1;, score=0.521 total time=  11.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.515 total time=   4.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.508 total time=   4.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.8;, score=0.514 total time=  14.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8;, score=0.529 total time=   4.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1;, score=0.499 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.8;, score=0.510 total time=  14.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.8;, score=0.524 total time=  14.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=300, subsample=1;, score=0.494 total time=  15.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=300, subsample=1;, score=0.503 total time=  16.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1;, score=0.527 total time=   5.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=100, subsample=1;, score=0.494 total time=   5.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=300, subsample=1;, score=0.508 total time=  15.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8;, score=0.506 total time=   9.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8;, score=0.518 total time=   9.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=0.8;, score=0.533 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1;, score=0.504 total time=  10.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1;, score=0.518 total time=  10.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=200, subsample=1;, score=0.528 total time=  10.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8;, score=0.523 total time=  14.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8;, score=0.506 total time=  14.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.517 total time=   7.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.503 total time=   7.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.8;, score=0.522 total time=  14.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1;, score=0.523 total time=  15.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1;, score=0.491 total time=  15.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8;, score=0.522 total time=   7.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1;, score=0.511 total time=   7.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1;, score=0.502 total time=   7.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=1;, score=0.522 total time=   7.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, min_child_weight=5, n_estimators=300, subsample=1;, score=0.525 total time=  14.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.8;, score=0.521 total time=  14.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.8;, score=0.504 total time=  13.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.8;, score=0.517 total time=  13.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=1;, score=0.524 total time=  15.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=1;, score=0.503 total time=  14.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m xgb_classifier \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier(eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogloss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mxgb_classifier, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hunterlanier/AI-Text-Detection/Models/Model_0.2.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Parameters:\u001b[39m\u001b[39m\"\u001b[39m, grid_search\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameter Grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1]\n",
    "}\n",
    "xgb_classifier = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, n_jobs=-1,verbose=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e4ec916",
   "metadata": {
    "papermill": {
     "duration": 0.007279,
     "end_time": "2023-12-03T04:25:10.839366",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.832087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c17c82e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:10.856839Z",
     "iopub.status.busy": "2023-12-03T04:25:10.856211Z",
     "iopub.status.idle": "2023-12-03T04:25:18.603769Z",
     "shell.execute_reply": "2023-12-03T04:25:18.602281Z"
    },
    "papermill": {
     "duration": 7.759967,
     "end_time": "2023-12-03T04:25:18.607075",
     "exception": false,
     "start_time": "2023-12-03T04:25:10.847108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c19629b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-03T04:25:18.624721Z",
     "iopub.status.busy": "2023-12-03T04:25:18.624313Z",
     "iopub.status.idle": "2023-12-03T04:25:18.637611Z",
     "shell.execute_reply": "2023-12-03T04:25:18.636194Z"
    },
    "papermill": {
     "duration": 0.025456,
     "end_time": "2023-12-03T04:25:18.640423",
     "exception": false,
     "start_time": "2023-12-03T04:25:18.614967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.999347\n",
       "1  1111bbbb   0.999347\n",
       "2  2222cccc   0.999347"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "probabilities = xgb_model.predict_proba(X_test)[:, 1]  # For probabilities\n",
    "predictions = xgb_model.predict(X_test)  # For class labels\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Ensure this is the correct ID column from your test set\n",
    "    'generated': probabilities\n",
    "})\n",
    "\n",
    "# Save to CSV file\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3937441,
     "sourceId": 6868189,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.98052,
   "end_time": "2023-12-03T04:25:19.709022",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-03T04:25:01.728502",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
